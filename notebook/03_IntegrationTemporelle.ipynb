{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Résolution d'EDO en temps\n",
    "\n",
    "**Basile Marchand (basile.marchand@mines-paristech.fr)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Intégration numérique ?**\n",
    "\n",
    "Considérons la forme générale d'une EDO du premier ordre\n",
    "$$ \\dot{\\mathbf{q}} = \\mathbf{B}( \\mathbf{q}, t), \\;\\; \\mathbf{q}\\in \\mathbb{R}^n$$\n",
    "On cherche alors à déterminer $\\mathbf{q}(t)\\in\\mathbb{R}^n,\\; \\forall t \\in [0,T]$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La question :   \n",
    "Comment faire travailler l'ordinateur à notre place ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pour information :  \n",
    "Il est possible également de traiter le cas d'EDO du second order par des méthodes dédiées (Newmark par exemple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Mais ça sert à quoi ?**\n",
    "\n",
    "De manière générale, il existe de nombreux cas de figures où l'on ne sait pas trouver de solution analytique à une EDO.  \n",
    "\n",
    "\n",
    "En mécanique de nombreuses lois de comportement s'expriment sous la forme d'EDO en temps. Traduisant de fait l'impact de l'histoire sur l'état actuel.\n",
    "\n",
    "Il existe toute un zoologie de méthodes d'intégration temporelle. Mais dans le cadre de ce cours on se limite aux méthodes les plus utilisées en mécanique à savoir :\n",
    "\n",
    "- La $\\theta$-méthode\n",
    "- La méthode de Runge-Kutta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### La notion de discrétisation en temps \n",
    "\n",
    "Pour tous les schémas d'intégration il est nécessaire de se donner une discrétisation en temps.\n",
    "On découpe donc l'intervalle de temps $[t\\_{init}, t\\_{end}]$ en $n$ intervalles de même taille **ou non**\n",
    "\n",
    "\n",
    "<media src=\"./media/integration/discretisation.png\" width=\"800\"></media>\n",
    "\n",
    "$$ \\Delta t_{i} =  t_{i+1} - t_{i}  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### La $\\theta$-méthode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**L'idée de base**\n",
    "\n",
    "La $\\theta$-méthode repose sur une évaluation de la dérivée temporelle par *différences finies* complétée par une évaluation de l'EDO en $t_\\theta$\n",
    "\n",
    "$$ t_\\theta = (1-\\theta) t_i + \\theta t_{i+1} \\; ; \\;  \\mathbf{q}_\\theta = (1-\\theta) \\mathbf{q}_i + \\theta \\mathbf{q}_{i+1} $$\n",
    "\n",
    "\n",
    "Le schéma numérique ainsi construit s'exprime :   \n",
    "$$ \\dfrac{ \\mathbf{q}_{i+1} - \\mathbf{q}_i }{\\Delta t} = \\mathbf{B}( \\mathbf{q}_\\theta  , t_\\theta ) $$\n",
    "\n",
    "La $\\theta$-méthode regroupe entre autres les trois méthodes suivantes :\n",
    "- Euler explicite $ (\\theta=0) $\n",
    "- Cranck-Nicholson $ (\\theta=0.5 )$\n",
    "- Euler implicite $ (\\theta=1) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**La méthode d'Euler explicite $(\\theta=0)$**\n",
    "\n",
    "On considère la dérivée au début de l'intervalle de temps\n",
    "$$ \\dfrac{ \\mathbf{q}_{i+1} - \\mathbf{q}_i }{\\Delta t} = \\mathbf{B}( \\mathbf{q}_i  , t_i ) $$\n",
    "Ce  qui permet d'écrire la suite :\n",
    "$$ \\mathbf{q}_{i+1} = \\mathbf{q}_{i} + \\Delta t \\mathbf{B}( \\mathbf{q}_i  , t_i ) $$\n",
    "La résolution est immédiate ! Connaissant $\\mathbf{q}_{i}$ on peut immédiatement déterminer $\\mathbf{q}_{i+1}$.  \n",
    "\n",
    "En revanche attention au pas de temps. Car la méthode est conditionellemnt stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**La méthode de Cranck-Nicholson $(\\theta = 0.5)$**\n",
    "\n",
    "\n",
    "La méthode de Crank-Nicholson est similaire à une formule de quadrature par la méthode des trapèzes pour les EDO linéaires.\n",
    "\n",
    "$$\\mathbf{q}_{i+1} = \\mathbf{q}_i + \\Delta t \\mathbf{B}\\left( \\frac{\\mathbf{q}_i+\\mathbf{q}_{i+1}}{2}, \\frac{t_i + t_{i+1}}{2} \\right)$$\n",
    "Cette méthode est d'ordre 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**La méthode d'Euler implicite $(\\theta = 1)$**\n",
    "\n",
    "On considère la dérivée à la fin de l'intervalle de temps\n",
    "$$ \\dfrac{ \\mathbf{q}_{i+1} - \\mathbf{q}_i }{\\Delta t} = \\mathbf{B}( \\mathbf{q}_{i+1}  , t_i ) $$\n",
    "Ce  qui permet d'écrire la suite :\n",
    "$$ \\mathbf{q}_{i+1} = \\mathbf{q}_{i} + \\Delta t \\mathbf{B}( \\mathbf{q}_{i+1}  , t_{i+1} ) $$\n",
    "Problème **non-linéaire** !!   \n",
    "Nécessite la résolution par une méthode de Newton et donc le calcul d'une matrice jacobienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Synthèse dans le cas d'une EDO linéaire**\n",
    "\n",
    "Dans le cas où l'opérateur $\\mathbf{B}$ est **linéaire** on peut nécessairement écrire l'EDO sous la forme :\n",
    "\n",
    "$$ \\mathbf{C} \\mathbf{\\dot{q}} = \\mathbf{K}\\cdot \\mathbf{q} + \\mathbf{F}(t) $$\n",
    "\n",
    "Dans ce cas la $\\theta$-méthode se ramène à la résolution de systèmes linéaire :\n",
    "\n",
    "$$ \\left( \\frac{1}{\\Delta t} \\mathbf{C} + \\theta \\mathbf{K} \\right) \\cdot \\mathbf{q}_{i+1} =  \\left( \\frac{1}{\\Delta t} \\mathbf{C} + (1-\\theta) \\mathbf{K} \\right) \\cdot \\mathbf{q}_{i} + (1-\\theta) \\mathbf{F}_{i} + \\theta \\mathbf{F}_{i+1} $$\n",
    "\n",
    "Dans le cas de pas de temps **constant** il est fortement recommandé de calculer une factorisation de  $\\left( \\frac{1}{\\Delta t} \\mathbf{C} + \\theta \\mathbf{K} \\right)$ en phase préliminaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Retour sur le Euler implicite**\n",
    "\n",
    "$$ \\mathbf{q}_{i+1} = \\mathbf{q}_{i} + \\Delta t \\mathbf{B}( \\mathbf{q}_{i+1}  , t_{i+1} ) $$\n",
    "Le problème à résoudre est non-linéaire !  \n",
    "A chaque incrément on doit résoudre\n",
    "$$ \\mathbf{G}(\\mathbf{q}_{i+1} ) = \\mathbf{q}_{i+1} - \\mathbf{q}_{i} - \\Delta t \\mathbf{B}( \\mathbf{q}_{i+1}  , t\\_{i+1} ) = 0 $$\n",
    "\n",
    "On applique alors une méthode de Newton :\n",
    "\n",
    "$$ \\mathbf{q}_{i+1}^{(k+1)} =   \\mathbf{q}_{i+1}^{(k)} + \\mathcal{J}^{-1}( \\mathbf{G}( \\mathbf{q}_{i+1}^{(k)} ) ) \\cdot  \\mathbf{G}(\\mathbf{q}_{i+1}^{(k)}) $$\n",
    "\n",
    "Avec $\\mathcal{J}( \\mathbf{F}( \\mathbf{q}_{i+1}^{(k)} ) )$ la matrice Jacobienne définie par :\n",
    "$$\\mathcal{J}( \\mathbf{G}( \\mathbf{q}_{i+1}^{(k)} )) = \\left. \\frac{ \\partial G }{\\partial \\mathbf{q}}\\right\\vert_{ \\mathbf{q}_{i+1}^{(k)}}  $$\n",
    "\n",
    "Dans la pratique deux approches pour calculer la matrice jacobienne :\n",
    "- Calcul analytique\n",
    "- Par perturbation\n",
    "\n",
    "Pour plus de détails revoir le cours précédent sur la résolution de systèmes non-linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Quelques propriétés mathématiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Existence, unicité et convergence**\n",
    "\n",
    "*Existence et unicité :* en associant une condition initiale $\\mathbf{q}_0$ ont obtient un problème de Cauchy  \n",
    "\n",
    "$$ \\begin{cases} \\dot{\\mathbf{q}} &= \\mathbf{B}( \\mathbf{q}, t) \\newline \\mathbf{q}(t_0) &= \\mathbf{q}_0 \\end{cases}$$\n",
    "\n",
    "\n",
    "Le thérorème de Cauchy-Lipchitz stipule alors que :\n",
    "\n",
    "*Si on connait $\\mathbf{q}\\_0$ et si $\\mathbf{B}(\\mathbf{q}, t)$ est localement lipchitzienne par rapport à la première variable alors la solution existe et elle est unique*\n",
    "\n",
    "$$ \\exists k \\in \\mathbb{R}^{+},\\, \\forall  t > t\\_0,\\, \\forall (\\mathbf{q}^1, \\mathbf{q}^2) $$\n",
    "$$ \\Vert \\mathbf{B}( \\mathbf{q}^2, t ) - \\mathbf{B}(\\mathbf{q}^1, t) \\Vert \\leq k \\Vert \\mathbf{q}^2 - \\mathbf{q}^1 \\Vert $$\n",
    "\n",
    "\n",
    "\n",
    "Théorème de Lax :  \n",
    "_Un schéma numérique aux différences finis est convergent s'il est **consistant** et **stable**._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Consistance d'un schéma numérique**\n",
    "\n",
    "\n",
    "Une méthode d'intégration temporelle est *consistante* si et seulement si elle engendre une suite $\\lbrace \\mathbf{q}_{i} \\rbrace_{i=1,...,n}$ telle que\n",
    "$$ \\lim_{\\Delta t \\rightarrow 0} \\frac{ \\mathbf{q}(t_{i+1}) - \\mathbf{q}(t_{i}) }{\\Delta t} = \\mathbf{\\dot{q}}(t_i) $$\n",
    "\n",
    "La consistance d'une méthode d'intégration est une condition nécessaire de convergence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Stabilité d'un schéma numérique**\n",
    "\n",
    "Une méthode d'intégration est stable si une petite variation du vecteur d'état à l'instant $t_i$ n'entraîne que des variations consécutives qui ne sont pas croissantes au cours du temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Stabilité de la $\\theta$-méthode** : cas de la diffusion\n",
    "    \n",
    "Soit un barreau soumis en $x=0$ à une température imposée et en $x=L$ à un flux imposé.  \n",
    "\n",
    "La discrétisation d'un tel problème permet d'écrire le système\n",
    "$$ \\mathbf{C}\\cdot \\mathbf{\\dot{q}} + \\mathbf{K}\\cdot \\mathbf{q} = \\mathbf{F} $$\n",
    "Où les différents opérateurs sont définis :\n",
    "$$ C_{ij} = \\rho C_p \\frac{h}{4} ( 2 \\delta_{ij} + \\delta_{(i-1)j}  + \\delta_{(i+1)j} )\\; ; \\; C_{1j} = \\rho C_p \\frac{h}{4} (\\delta_{1j} + \\delta_{2j} ) $$  \n",
    "$$ K_{ij} =  \\frac{k}{h} ( 2 \\delta_{ij} - \\delta_{(i-1)j}  - \\delta_{(i+1)j} )\\; ; \\; K_{1j} = \\frac{k}{h} (\\delta_{1j} - \\delta_{2j} ) \\; ; \\; F_{i}  = T^d \\delta_{(N)i} $$\n",
    "\n",
    "Avec $\\delta_{ij}$ le symbole de Kronecker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Illustration**\n",
    "\n",
    "***TODO***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Astuce : changement de variable par projection dans une base de vecteurs propres:\n",
    "$$\\exists \\boldsymbol{\\phi}_k \\in \\mathbb{R}^N, \\: \\lambda_k \\in \\mathbb{R}^+, \\; - \\lambda_k \\: \\mathbf{C} \\: \\boldsymbol{\\phi}_k + \\mathbf{K} \\boldsymbol{\\phi}_k = 0 $$\n",
    "\n",
    "$$\\exists \\mathbf{y} \\in \\mathbb{R}^N, \\; \\mathbf{q} = \\sum_{k=1}^N \\phi_k \\: y_k = \\boldsymbol{\\phi} \\mathbf{y}, \\; \\boldsymbol{\\phi} = [\\phi_1, ...,\\phi_N] \\in \\mathbb{R}^{N\\times N}$$\n",
    "On en déduit:\n",
    "$$\\dot{\\mathbf{y}} = \\boldsymbol{\\phi}^T \\mathbf{C} \\mathbf{B}( \\boldsymbol{\\phi} \\mathbf{y} , t)$$\n",
    "Donc:\n",
    "$$\\dot{\\mathbf{y}} = - \\boldsymbol{\\phi}^T \\mathbf{K} \\boldsymbol{\\phi} \\mathbf{y} + \\boldsymbol{\\phi}^T \\mathbf{F}$$\n",
    "avec $(\\boldsymbol{\\phi}^T \\mathbf{K} \\boldsymbol{\\phi})_{ij} = \\lambda_{i} \\delta_{ij}$. Il s'agit donc d'un système d'équations découplées.  \n",
    "\n",
    "Considérons l'effet d'une perturbation à la ligne $k$ :\n",
    "$$ \\dot{y}^{(k)} = - \\lambda^{(k)} y^{(k)} + F^{(k)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Appliquons la $\\theta$-méthode à la ligne $k$:\n",
    "$$\\dot{y}^{(k)} = - \\lambda^{(k)}  y^{(k)} + F^{(k)}$$\n",
    "devient\n",
    "$$\\frac{y_{i+1}^{(k)} - y_{i}^{(k)}}{\\Delta t} = -\\lambda^{(k)} ( (1-\\theta) y_{i}^{(k)} + \\theta y_{i+1}^{(k)}) + (1-\\theta) F_{i}^{(k)} + \\theta F_{i+1}^{(k)}$$\n",
    "$$ \\Rightarrow  ( 1 + \\Delta t \\theta  \\lambda^{(k)} )  y_{i+1}^{(k)} = (1 - \\Delta t \\: (1-\\theta) \\: \\lambda^{(k)}) \\: y_{i}^{(k)} + \\Delta t \\: ( (1-\\theta) \\: F_{i}^{(k)} + \\theta \\: F_{i+1}^{(k)})$$\n",
    "Considérons l'effet d'un petite perturbation $\\delta y_{i}^{(k)}$ en $t_i$ pour la ligne $k$. On obtient l'équation d'évolution de la perturbation:\n",
    "$$( 1 + \\Delta t \\: \\theta \\: \\lambda^{(k)} ) \\: \\delta y_{i+1}^{(k)} = (1 - \\Delta t \\: (1-\\theta) \\: \\lambda^{(k)}) \\: \\delta y_{i}^{(k)}$$\n",
    "Le coefficient d'amplification est donc:\n",
    "$$\\mathcal{A}^{(k)} = \\frac{1 + \\Delta t \\: (\\theta - 1) \\: \\lambda^{(k)}}{1 + \\Delta t \\: \\theta \\: \\lambda^{(k)}}, \\quad \\delta y_{i+1}^{(k)} = \\mathcal{A}^{(k)}  \\: \\delta y_{i}^{(k)} $$\n",
    "Si $\\max_{k} |  \\frac{1 + \\Delta t \\: (\\theta - 1) \\: \\lambda^{(k)}}{1 + \\Delta t \\: \\theta \\: \\lambda^{(k)}} | < 1$ alors il n'y a pas d'amplification de perturbation et donc le schéma est stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Cas linéaire**\n",
    "\n",
    "$$ \\frac{1 + \\Delta t \\: (\\theta - 1) \\: \\lambda^{(k)}}{1 + \\Delta t \\: \\theta \\: \\lambda^{(k)}} =  1 - \\frac{\\lambda^{(k)}}{1 + \\Delta t \\: \\theta \\: \\lambda^{(k)}} < 1$$\n",
    "\n",
    "Existe-t-il une valeur de $\\Delta t > 0$, notée $\\Delta t_{c}^{(k)}$ telle que:\n",
    "$$ \\frac{1 + \\Delta t_{c}^{(k)} \\: (\\theta - 1) \\: \\lambda^{(k)}}{1 + \\Delta t_{c}^{(k)} \\: \\theta \\: \\lambda^{(k)}} =  -1 $$\n",
    "$$ \\Rightarrow \\: 1 + \\Delta t_{c}^{(k)} \\: (\\theta - 1) \\: \\lambda^{(k)} +  1 + \\Delta t_{c}^{(k)} \\: \\theta \\: \\lambda^{(k)} = 0 $$\n",
    "$$ \\Rightarrow \\: 2 + \\Delta t_{c}^{(k)} \\: ( 2 \\: \\theta - 1) \\: \\lambda^{(k)} = 0 $$\n",
    "Si $ \\theta < \\frac{1}{2}$, il existe $\\Delta t_{c} > 0 $ tel que:\n",
    "$$ \\Delta t_{c} = \\min_k \\frac{1}{(\\frac{1}{2} - \\theta) \\: \\lambda^{(k)} } = \\frac{1}{(\\frac{1}{2} - \\theta) \\: \\max_k \\lambda^{(k)} }$$\n",
    "\n",
    "Si $\\theta \\ge \\frac{1}{2}$, on a $\\max_k | \\mathcal{A}_k | < 1$. Le schéma est stable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si $\\theta < \\frac{1}{2}$, comment choisir $\\Delta t$? \n",
    "\n",
    "Nous souhaitons avoir $\\mathcal{A}^{(k)} > -1$:\n",
    "\n",
    "$$1 + \\Delta t \\: (\\theta - 1) \\: \\lambda^{(k)} > -1 - \\Delta t \\: \\theta \\: \\lambda^{(k)}$$\n",
    "$$\\Rightarrow \\: 2 + \\Delta t \\: (2 \\: \\theta - 1) \\: \\lambda^{(k)} > 0$$\n",
    "$$\\Rightarrow \\:  \\Delta t  \\: \\lambda^{(k)} < \\frac{-2}{(2 \\: \\theta - 1)}$$\n",
    "$$\\Rightarrow \\:  \\Delta t   < \\frac{-2}{(2 \\: \\theta - 1) \\: \\lambda^{(k)}} \\: \\forall k=1, ...,N$$\n",
    "\n",
    "Il faut donc $\\Delta t < \\Delta t_{c}$.  \n",
    "La $\\theta$-méthode est stable pour $\\theta \\ge \\frac{1}{2}$. Donc Euler implicite et Crank-Nicholson sont des schémas stables.  \n",
    "La $\\theta$-méthode est conditionnellement stable pour $\\theta < \\frac{1}{2}$. Il faut déterminer un **pas de temps critique** $\\Delta t\\_c$ et choisir $\\Delta t < \\Delta t\\\n",
    "_c$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Retour sur le problème de diffusion**\n",
    "\n",
    "Dans le cas du problème parabolique de diffusion thermique, les valeurs propres $\\lambda^{(k)}$ dépendent de $h$, la taille des éléments. On peut alors introduire le coefficient CFL (Courant–Friedrichs–Lewy):\n",
    "$$\\beta = \\frac{k}{\\rho \\: C_p} \\: \\frac{\\Delta t}{h^2}$$\n",
    "Une estimation de $\\max_k \\lambda^{(k)}$ peut être obtenue avec la plus grande valeur propre du plus petit élément pris de façon isolée (théorème de Irons et Threhane).\n",
    "\n",
    "On obtient ici:\n",
    "\n",
    "$$\\max_k \\lambda^{(k)} \\approx \\frac{8 \\: k}{\\rho \\: C_p \\: h^2}$$\n",
    "\n",
    "On en déduit:\n",
    "\n",
    "$$\\Delta t_c = \\frac{ \\rho \\: C_p \\: h^2 }{\\left(\\frac{1}{2} - \\theta\\right) \\: 8 \\: k }$$\n",
    "Plus le plus petit élément est petit, plus il faut réduire le pas de temps pour $\\theta < \\frac{1}{2}$.\n",
    "\n",
    "Dans le cas étudié, on a:\n",
    "$$\\frac{\\Delta t}{\\Delta t_c} = \\left(\\frac{1}{2} - \\theta \\right) \\: 8 \\: \\beta$$\n",
    "La condition CFL est donc:\n",
    "$$ \\left(\\frac{1}{2} - \\theta\\right) \\: 8 \\: \\frac{k}{\\rho \\: C_p} \\: \\frac{\\Delta t}{h^2} < 1$$\n",
    "pour avoir un schéma stable. Si $\\theta < \\frac{1}{2}$ plus $h$ est petit pour capter de forts gradients, plus il faut $\\Delta t$ petit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Méthode de Runge-Kutta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**L'idée de base**\n",
    "\n",
    "\n",
    "Parfois l'emploi de la méthode d'Euler implicite est impossible et la résolution avec un Euler explicite couteraît trop cher. \n",
    "\n",
    "\n",
    "Principe de la méthode :\n",
    "- Prédiction\n",
    "- Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Runge-Kutta d'ordre 2 (RK2)***\n",
    "\n",
    "Le principe est d'estimer la dérivée au milieu du pas d'intégration\n",
    "\n",
    "La prévision est construite à partir de **deux** évaluations de la fonction $\\mathbf{B}$\n",
    "\n",
    "$$ \\begin{cases}\n",
    "\\delta_1 \\mathbf{q} &=& \\Delta t \\: \\mathbf{B}( \\mathbf{q}_i, \\: t_i) \\newline\n",
    "\\delta_2 \\mathbf{q} &=& \\Delta t \\: \\mathbf{B}( \\mathbf{q}_i + \\frac{\\delta_1 \\mathbf{q}}{2} , \\: t_i+\\frac{ \\Delta t}{2}) \\newline\n",
    "\\mathbf{q}_{i+1} &=& \\mathbf{q}_i + \\delta_2 \\mathbf{q} + o(\\Delta t^2)\n",
    "\\end{cases} $$\n",
    "\n",
    "$\\delta_1 \\mathbf{q}$ est l'incrément calculé par la méthode d'Euler explicite. \n",
    "\n",
    "Ce schéma annule le premier ordre de l'erreur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Runge-Kutta d'ordre 4 (RK4)***\n",
    "\n",
    "La prévision est construite avec **quatre** évaluations de la fonction $\\mathbf{B}$:\n",
    "\n",
    "$$ \\begin{cases}\n",
    "\\delta_1 \\mathbf{q} &=& \\Delta t \\: \\mathbf{B}( \\mathbf{q}_i, \\: t_i) \\newline\n",
    "\\delta_2 \\mathbf{q} &=& \\Delta t \\: \\mathbf{B}( \\mathbf{q}_i + \\frac{\\delta_1 \\mathbf{q}}{2} , \\: t_i+\\frac{ \\Delta t }{2}) \\newline\n",
    "\\delta_3 \\mathbf{q} &=& \\Delta t \\: \\mathbf{B}( \\mathbf{q}_i + \\frac{\\delta_2 \\mathbf{q}}{2} , \\: t_i+\\frac{ \\Delta t }{2}) \\newline\n",
    "\\delta_4 \\mathbf{q} &=& \\Delta t \\: \\mathbf{B}( \\mathbf{q}_i + \\delta_3 \\mathbf{q}, \\: t_i+\\Delta t) \\newline\n",
    "\\mathbf{q}_{i+1} &=& \\mathbf{q}_i + \\frac{ \\delta_1 \\mathbf{q}}{6} + \\frac{ \\delta_2 \\mathbf{q}}{3} + \\frac{ \\delta_3 \\mathbf{q}}{3} + \\frac{ \\delta_4 \\mathbf{q}}{6} + o(\\Delta t^4)\n",
    "\\end{cases} $$\n",
    "\n",
    "**Remarque** sur la complexité numérique:   \n",
    "\n",
    "Les pas de temps utilisés pour ce schéma ne sont pas nécessairement deux fois plus grands que ceux utilisés pour le schéma du second ordre. Mais s'ils le sont la complexité numérique du schéma est moins grande que celle de RK2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Contrôle du pas de temps**\n",
    "\n",
    "Approche empirique pour évaluer la convergence de l'approximation:\n",
    "1. diviser la taille du  pas de temps par 2\n",
    "2. comparer les prévisions\n",
    "3. recommencer tant que l'écart entre les deux dernières prévisions est jugé trop important.\n",
    "\n",
    "Mais en général l'erreur d'approximation ne converge pas de façon uniforme sur tout l'intervalle de temps.  \n",
    "Il est parfois utile de concentrer les petits pas de temps en certains endroits de l'intervalle de temps.\n",
    "\n",
    "Une méthode **adaptative** de pas de temps permet de mieux répartir sur l'intervalle de temps les erreurs d'approximation en ayant le souci de réduire les temps de calcul. L'adaptation des pas de temps permet aussi de faciliter la linéarisation de certains problèmes d'évolution non linéaires.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "***Approche par extrapolation locale [Press94].***\n",
    "\n",
    "<media src=\"./media/integration/adaptation.png\" width=\"400\"></media>\n",
    "\n",
    "En doublant le pas de temps, on estime la solution exacte $\\overline{\\mathbf{q}}$ de deux façons par RK4:\n",
    "$$\\overline{\\mathbf{q}}(t_i + (2\\Delta t)) = \\mathbf{q}_{i+1} + o( (2 \\Delta t)^4)$$\n",
    "$$\\overline{\\mathbf{q}}(t_i + \\Delta t + \\Delta t) = \\mathbf{q}_{i+1} + o( \\Delta t^4)$$\n",
    "On suppose qu'il existe $ c \\in \\mathbb{R} $ tel que:\n",
    "$$\\overline{\\mathbf{q}}(t_i + (2\\Delta t)) = \\mathbf{q}_{i+1} + c \\: (2 \\Delta t)^5 + o( (2 \\Delta t)^5)$$\n",
    "$$\\overline{\\mathbf{q}}(t_i + \\Delta t + \\Delta t) = \\widetilde{\\mathbf{q}}_{i+1} + 2 \\: c \\: \\Delta t^5 + o( \\Delta t^5)$$\n",
    "En supposant négligeable l'ordre 5, on estime l'erreur selon:\n",
    "$$\\Delta \\mathbf{q} = \\widetilde{\\mathbf{q}}_{i+1} - \\mathbf{q}_{i+1}, \\: \\eta = \\max_i \\vert \\Delta \\mathbf{q}_i \\vert, \\quad \\eta = 30 \\: c \\: \\Delta t^5$$\n",
    "On souhaite connaitre le pas de temps $\\Delta t^\\star$ qui permet d'avoir une erreur $\\eta^\\star = \\epsilon\\_{tol}$ si $\\eta > \\epsilon\\_{tol}$, tel que:\n",
    "$$\\eta^\\star = 30 \\: c \\:  \\Delta t^{\\star 5}$$\n",
    "On en déduit le pas de temps adapté : $\\Delta t^\\star = \\Delta t \\: (\\frac{\\eta}{\\epsilon\\_{tol}})^{1/5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Le contrôle du pas de temps passe par une estimation de l'erreur\n",
    "\n",
    "***Il y a donc un coût additionnel !!***\n",
    "\n",
    "\n",
    "C'est néanmoins très utile voir impératif\n",
    "\n",
    "***Cela permet d'optimiser les coûts de calcul***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de Maxwell\n",
    "$$ \\dot{\\varepsilon} = \\frac{1}{E} \\dot{\\sigma} + \\frac{1}{\\eta} \\sigma $$\n",
    "avec $\\varepsilon(t)=10^{-3} t$ imposé et $\\sigma(t=0) = 0$\n",
    "\n",
    "1. Calculer la solution analytique \n",
    "2. Déterminer la solution par une approche Euler explicite\n",
    "3. Déterminer la solution par une approche Euler implicite\n",
    "4. Faire de même avec la méthode RK4\n",
    "5. Utiliser `scipy.integrate.ode` pour calculer la solution de ce problème et comparer\n",
    "\n",
    "Données : $\\eta = 1000\\,MPa.s$, $E=20000\\,MPa$, $T=10\\,s$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "rise": {
   "autolaunch": true,
   "slideNumber": "c/t",
   "theme": "moon",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
